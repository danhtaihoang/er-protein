{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4190, 50)\n"
     ]
    }
   ],
   "source": [
    "pfam_id = 'PF00200'\n",
    "#pfam_id = sys.argv[1]\n",
    "\n",
    "s0 = np.loadtxt('../pfam_50_80pos/%s_s0.txt'%(pfam_id)).astype(int)\n",
    "print(s0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_var = s0.shape[1]\n",
    "mx = np.array([len(np.unique(s0[:,i])) for i in range(n_var)])\n",
    "mx_cumsum = np.insert(mx.cumsum(),0,0)\n",
    "i1i2 = np.stack([mx_cumsum[:-1],mx_cumsum[1:]]).T \n",
    "\n",
    "mx_sum = mx.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4190, 677)\n"
     ]
    }
   ],
   "source": [
    "onehot_encoder = OneHotEncoder(sparse=False,categories='auto')\n",
    "#onehot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "s = onehot_encoder.fit_transform(s0)\n",
    "print(s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming(seq1,seq2):\n",
    "    \"\"\"\n",
    "    Return the Hamming distance between two sequences (of any kind).\n",
    "    \"\"\"\n",
    "\n",
    "    d = np.sum(np.array(seq1)!=np.array(seq2))\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seqreweight(msa,threshold=1.0):\n",
    "    \"\"\"\n",
    "    Return weighting for a set of sequences based on similarity.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sequence reweighting (similarity)\n",
    "    \n",
    "    Beff=1.0\n",
    "    weight=np.array([1.0 for i in range(len(msa))])\n",
    "\n",
    "    thresh=int((1.0 - threshold) * len(msa[0]))\n",
    "    for i in range(len(msa)):\n",
    "        for j in range(i+1,len(msa)):\n",
    "            if hamming(msa[i],msa[j])<thresh:\n",
    "                weight[i]+=1.0\n",
    "                weight[j]+=1.0\n",
    "    weight=1.0/weight\n",
    "    Beff=weight.sum(0)\n",
    "        \n",
    "    return Beff, weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "msa = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = 0.2\n",
    "threshold = 1 - theta\n",
    "\n",
    "Beff,weight = seqreweight(msa, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove sites with no variation\n",
    "p1      = np.sum(weight * msa.T, axis=1) / Beff\n",
    "nonsing = (p1>0) * (p1<1)\n",
    "\n",
    "#if removeSingular:\n",
    "#    msa = msa[:,nonsing]\n",
    "#    N = len(msa[0])\n",
    "\n",
    "# Compute correlations\n",
    "p12 = np.einsum('i,ij,ik->jk', weight, msa, msa) / Beff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ia = p1      # for convenience\n",
    "p_iajb = p12   # for convenience\n",
    "\n",
    "# print frequency and correlation\n",
    "with open('%s/cov.p'%pfam_id,'a') as f:\n",
    "    # p_ia:\n",
    "    for i0 in range(n_var):\n",
    "        i1,i2 = i1i2[i0,0],i1i2[i0,1]\n",
    "\n",
    "        f.write(\" \".join([str(p_ia[ia]) for ia in range(i1,i2-1)])+\"\\n\") # (exclude the last state)\n",
    "\n",
    "    # p_iajb:\n",
    "    for i0 in range(n_var-1):\n",
    "        i1,i2 = i1i2[i0,0],i1i2[i0,1]\n",
    "\n",
    "        for j0 in range(i0+1,n_var):\n",
    "            j1,j2 = i1i2[j0,0],i1i2[j0,1]\n",
    "\n",
    "            f.write(\" \".join([str(p_iajb[ia,jb]) for ia in range(i1,i2-1)\\\n",
    "                              for jb in range(j1,j2-1)])+\"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find ia_tab, jb_tab\n",
    "nrow = int(n_var*(n_var-1)/2.) \n",
    "ncol = int(19*19)\n",
    "\n",
    "ia_tab = np.zeros((nrow,ncol)).astype(int)\n",
    "jb_tab = np.zeros((nrow,ncol)).astype(int)\n",
    "\n",
    "# row\n",
    "irow = 0\n",
    "for i0 in range(n_var-1):\n",
    "    i1,i2 = i1i2[i0,0],i1i2[i0,1]\n",
    "\n",
    "    for j0 in range(i0+1,n_var):\n",
    "        j1,j2 = i1i2[j0,0],i1i2[j0,1]\n",
    "\n",
    "        # column\n",
    "        icol = 0\n",
    "        for ia in range(i1,i2-1):\n",
    "            for jb in range(j1,j2-1):\n",
    "                \n",
    "                ia_tab[irow,icol] = ia\n",
    "                jb_tab[irow,icol] = jb\n",
    "                \n",
    "                icol += 1\n",
    "        irow += 1\n",
    "                \n",
    "np.savetxt('%s/ia_tab.dat'%pfam_id,ia_tab,fmt='%i')                \n",
    "np.savetxt('%s/jb_tab.dat'%pfam_id,jb_tab,fmt='%i')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
